import gymnasium as gym
from maze_env import MazeEnv, load_custom_points
from stable_baselines3 import TD3
from stable_baselines3.common.noise import NormalActionNoise
import numpy as np
import os
import matplotlib.pyplot as plt

if __name__ == "__main__":
    # Load custom start/goal points if available
    start_pos, goal_pos = load_custom_points()
    env = MazeEnv(start_pos=start_pos, goal_pos=goal_pos)
    n_actions = env.action_space.shape[0]
    action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.2 * np.ones(n_actions))
    model = TD3(
        "MlpPolicy",
        env,
        action_noise=action_noise,
        learning_rate=2e-4,
        buffer_size=50000,
        learning_starts=1000,
        batch_size=128,
        tau=0.005,
        gamma=0.99,
        train_freq=1,
        gradient_steps=1,
        policy_delay=2,
        target_policy_noise=0.2,
        target_noise_clip=0.5,
        verbose=1,
        device='auto',
    )
    model.learn(total_timesteps=50000)
    # Track rewards and steps per episode
    episode_rewards = []
    episode_steps = []
    obs, info = env.reset()
    total_reward = 0
    steps = 0
    for t in range(50000):
        action, _ = model.predict(obs, deterministic=False)
        obs, reward, done, _, info = env.step(action)
        total_reward += reward
        steps += 1
        if done:
            episode_rewards.append(total_reward)
            episode_steps.append(steps)
            obs, info = env.reset()
            total_reward = 0
            steps = 0
    os.makedirs("saved_models", exist_ok=True)
    model.save("saved_models/td3_maze")
    print("Model saved to saved_models/td3_maze.zip")
    # Plot accumulated rewards
    plt.figure()
    plt.plot(episode_rewards)
    plt.xlabel('Episode')
    plt.ylabel('Accumulated Reward')
    plt.title('TD3 Maze: Accumulated Rewards per Episode')
    plt.grid(True)
    plt.savefig('visuals/td3_maze_rewards.png', dpi=200)
    # Plot steps per episode
    plt.figure()
    plt.plot(episode_steps)
    plt.xlabel('Episode')
    plt.ylabel('Steps Taken')
    plt.title('TD3 Maze: Steps per Episode')
    plt.grid(True)
    plt.savefig('visuals/td3_maze_steps.png', dpi=200)
    print('Plots saved to visuals/td3_maze_rewards.png and visuals/td3_maze_steps.png')

    # Visualize the final path generated by the trained agent
    obs, info = env.reset()
    path = [env.agent_pos.copy()]
    for _ in range(env.max_steps):
        action, _ = model.predict(obs, deterministic=True)
        obs, reward, done, _, info = env.step(action)
        path.append(env.agent_pos.copy())
        if done:
            break
    path = np.array(path)

    # Path smoothening methods
    def moving_average_path(path, window=3):
        if len(path) < window:
            return path
        x = np.convolve(path[:,0], np.ones(window)/window, mode='same')
        y = np.convolve(path[:,1], np.ones(window)/window, mode='same')
        return np.stack([x, y], axis=1)

    def bspline_path(path, s=2):
        from scipy.interpolate import splprep, splev
        if len(path) < 4:
            return path
        tck, u = splprep([path[:,0], path[:,1]], s=s)
        unew = np.linspace(0, 1, max(100, len(path)*3))
        out = splev(unew, tck)
        return np.array(list(zip(out[0], out[1])))

    # Original path
    plt.figure(figsize=(7,7))
    plt.imshow(env.obstacles.T, origin='lower', cmap='gray_r', alpha=0.5)
    plt.plot(path[:,0], path[:,1], 'g.-', label='Agent Path')
    plt.scatter(path[0,0], path[0,1], c='blue', s=100, label='Start')
    plt.scatter(env.goal_pos[0], env.goal_pos[1], c='red', s=100, label='Goal')
    plt.title('TD3 Maze: Final Path (Original)')
    plt.legend()
    plt.grid(True)
    plt.savefig('visuals/td3_maze_final_path.png', dpi=200)
    plt.show()

    # Moving average smoothened path
    smoothed_ma = moving_average_path(path)
    plt.figure(figsize=(7,7))
    plt.imshow(env.obstacles.T, origin='lower', cmap='gray_r', alpha=0.5)
    plt.plot(smoothed_ma[:,0], smoothed_ma[:,1], 'b-', label='Moving Average')
    plt.scatter(smoothed_ma[0,0], smoothed_ma[0,1], c='blue', s=100, label='Start')
    plt.scatter(env.goal_pos[0], env.goal_pos[1], c='red', s=100, label='Goal')
    plt.title('TD3 Maze: Moving Average Path')
    plt.legend()
    plt.grid(True)
    plt.savefig('visuals/td3_maze_final_path_moving_average.png', dpi=200)
    plt.show()

    # B-spline smoothened path
    try:
        smoothed_bspline = bspline_path(path)
        plt.figure(figsize=(7,7))
        plt.imshow(env.obstacles.T, origin='lower', cmap='gray_r', alpha=0.5)
        plt.plot(smoothed_bspline[:,0], smoothed_bspline[:,1], 'r-', label='B-spline')
        plt.scatter(smoothed_bspline[0,0], smoothed_bspline[0,1], c='blue', s=100, label='Start')
        plt.scatter(env.goal_pos[0], env.goal_pos[1], c='red', s=100, label='Goal')
        plt.title('TD3 Maze: B-spline Path')
        plt.legend()
        plt.grid(True)
        plt.savefig('visuals/td3_maze_final_path_bspline.png', dpi=200)
        plt.show()
    except Exception as e:
        print(f'B-spline smoothing failed: {e}')
    print('Final path plots saved to visuals/td3_maze_final_path.png, td3_maze_final_path_moving_average.png, td3_maze_final_path_bspline.png')
